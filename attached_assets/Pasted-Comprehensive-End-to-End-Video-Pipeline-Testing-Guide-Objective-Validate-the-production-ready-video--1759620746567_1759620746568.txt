Comprehensive End-to-End Video Pipeline Testing Guide
Objective
Validate the production-ready video pipeline with all implemented fixes: CMS upload ‚Üí Cloud transcoding ‚Üí GCS storage ‚Üí CDN delivery ‚Üí Playback with smart buffer management.

Pre-Test Setup
Environment Verification
bash
# 1. Verify Cloud Run deployment
gcloud run services describe video-transcoder --region=us-central1
# Should show: CPU: 4, Memory: 16Gi

# 2. Check GCS buckets exist
gsutil ls gs://ode-islands-video-input/
gsutil ls gs://ode-islands-video-cdn/

# 3. Verify API endpoints
curl -I http://localhost:3000/api/cms/media/upload
# Should return 405 (GET not allowed) or 401 (auth required)

# 4. Ensure test videos are ready
ls -la test_videos/
# sample_30s.mp4, sample_5min.mp4, sample_4k.mp4, corrupted.mp4, etc.
Test Suite
Test 1: Happy Path - Complete Upload to Playback
javascript
// test/e2e/happy-path.test.js
const happyPathTest = async () => {
  console.log('üé¨ TEST 1: Happy Path - Full Pipeline');
  
  // Step 1: Upload via CMS
  console.log('üì§ Step 1: Uploading video...');
  const formData = new FormData();
  formData.append('file', fs.createReadStream('test_videos/sample_30s.mp4'));
  formData.append('metadata', JSON.stringify({
    title: 'E2E Test Video',
    description: 'Testing complete pipeline'
  }));
  
  const uploadResponse = await fetch('/api/cms/media/upload', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${ADMIN_TOKEN}`
    },
    body: formData
  });
  
  assert(uploadResponse.status === 200, 'Upload should succeed');
  const { videoId, statusUrl } = await uploadResponse.json();
  console.log(`‚úÖ Upload successful - Video ID: ${videoId}`);
  
  // Step 2: Monitor Processing
  console.log('‚öôÔ∏è Step 2: Monitoring transcoding...');
  let status = 'processing';
  let attempts = 0;
  const maxAttempts = 60; // 5 minutes max
  
  while (status === 'processing' && attempts < maxAttempts) {
    await sleep(5000);
    const statusResponse = await fetch(statusUrl);
    const statusData = await statusResponse.json();
    
    console.log(`   Status: ${statusData.status}, Progress: ${statusData.profilesComplete || 0}/${statusData.totalProfiles || 11}`);
    
    status = statusData.status;
    attempts++;
    
    // Verify progress is incremental
    if (statusData.profilesComplete > 0) {
      assert(statusData.profilesComplete <= 11, 'Progress should not exceed total profiles');
    }
  }
  
  assert(status === 'completed', `Processing should complete, got: ${status}`);
  console.log('‚úÖ Transcoding completed');
  
  // Step 3: Verify Storage
  console.log('üíæ Step 3: Verifying storage...');
  const cdnBase = process.env.NEXT_PUBLIC_CDN_URL || 'https://storage.googleapis.com/ode-islands-video-cdn';
  
  // Check master playlist
  const masterUrl = `${cdnBase}/videos/${videoId}/manifest/master.m3u8`;
  const masterResponse = await fetch(masterUrl);
  assert(masterResponse.status === 200, 'Master playlist should exist');
  
  const masterContent = await masterResponse.text();
  
  // Verify all expected quality levels
  const expectedQualities = ['144p', '240p', '360p', '480p', '720p', '1080p'];
  for (const quality of expectedQualities) {
    assert(masterContent.includes(`${quality}/playlist.m3u8`), `Should include ${quality}`);
  }
  console.log('‚úÖ All quality levels present');
  
  // Step 4: Test Playback
  console.log('‚ñ∂Ô∏è Step 4: Testing playback...');
  const browser = await playwright.chromium.launch({ headless: false });
  const page = await browser.newPage();
  
  // Monitor console for buffer cleanup
  const bufferLogs = [];
  page.on('console', msg => {
    if (msg.text().includes('buffer')) {
      bufferLogs.push(msg.text());
    }
  });
  
  await page.goto(`http://localhost:3000/video/${videoId}`);
  
  // Wait for video element
  const video = await page.waitForSelector('video');
  
  // Start playback
  await video.click();
  
  // Play for 2.5 minutes to trigger buffer cleanup
  console.log('   Playing for 2.5 minutes to test buffer cleanup...');
  await page.waitForTimeout(150000); // 2.5 minutes
  
  // Check playback metrics
  const metrics = await page.evaluate(() => {
    const video = document.querySelector('video');
    return {
      currentTime: video.currentTime,
      buffered: video.buffered.length > 0 ? video.buffered.end(0) : 0,
      paused: video.paused,
      error: video.error
    };
  });
  
  assert(metrics.currentTime > 120, 'Should have played for 2+ minutes');
  assert(!metrics.paused, 'Should still be playing');
  assert(!metrics.error, 'Should have no errors');
  
  // Verify buffer cleanup occurred
  const cleanupLogs = bufferLogs.filter(log => 
    log.includes('Removing back buffer') || 
    log.includes('Back buffer removed')
  );
  assert(cleanupLogs.length > 0, 'Buffer cleanup should have triggered');
  console.log(`‚úÖ Buffer cleanup triggered ${cleanupLogs.length} times`);
  
  await browser.close();
  
  console.log('‚úÖ TEST 1 PASSED: Complete pipeline working');
  return { videoId, bufferCleanups: cleanupLogs.length };
};
Test 2: Error Handling - All Failure Scenarios
javascript
// test/e2e/error-handling.test.js
const errorHandlingTest = async () => {
  console.log('‚ùå TEST 2: Error Handling');
  
  // Test 2.1: Oversized File
  console.log('üìè Test 2.1: File too large...');
  const oversizedTest = await testOversizedFile();
  assert(oversizedTest.error.includes('2GB'), 'Should reject files > 2GB');
  
  // Test 2.2: Invalid File Type
  console.log('üìÑ Test 2.2: Invalid file type...');
  const invalidTypeTest = await testInvalidFileType();
  assert(invalidTypeTest.error.includes('file type'), 'Should reject non-video files');
  
  // Test 2.3: Corrupted Video
  console.log('üíî Test 2.3: Corrupted video...');
  const corruptedTest = await testCorruptedVideo();
  assert(corruptedTest.status === 'error' || corruptedTest.status === 'failed', 
    'Should handle corrupted videos gracefully');
  
  // Test 2.4: Server Error (500)
  console.log('üî• Test 2.4: Server error response...');
  const serverErrorTest = await testServerError();
  assert(serverErrorTest.errorDisplayed, 'Should display server errors to user');
  assert(!serverErrorTest.infinitePolling, 'Should stop polling on error');
  
  // Test 2.5: Network Failure
  console.log('üì° Test 2.5: Network failure...');
  const networkTest = await testNetworkFailure();
  assert(networkTest.errorHandled, 'Should handle network failures gracefully');
  
  console.log('‚úÖ TEST 2 PASSED: All errors handled correctly');
};

async function testServerError() {
  // Temporarily mock 500 response
  const page = await browser.newPage();
  
  // Intercept API calls
  await page.route('**/api/cms/media/upload/**', route => {
    route.fulfill({
      status: 500,
      contentType: 'application/json',
      body: JSON.stringify({ error: 'Transcoding service unavailable' })
    });
  });
  
  await page.goto('http://localhost:3000/cms/media-uploader');
  
  // Upload a file
  const fileInput = await page.$('input[type="file"]');
  await fileInput.setInputFiles('test_videos/sample_30s.mp4');
  
  // Wait for error message
  const errorElement = await page.waitForSelector('.error-message', { timeout: 10000 });
  const errorText = await errorElement.textContent();
  
  // Check polling stopped
  await page.waitForTimeout(10000);
  const spinnerStillVisible = await page.$('.processing-spinner');
  
  return {
    errorDisplayed: errorText.includes('Transcoding service unavailable'),
    infinitePolling: spinnerStillVisible !== null
  };
}
Test 3: Parallel Transcoding Performance
javascript
// test/e2e/parallel-performance.test.js
const parallelPerformanceTest = async () => {
  console.log('‚ö° TEST 3: Parallel Transcoding Performance');
  
  // Upload and measure transcoding time
  const testVideos = [
    { file: 'sample_30s.mp4', expectedTime: 45 },
    { file: 'sample_5min.mp4', expectedTime: 300 },
    { file: 'sample_10min.mp4', expectedTime: 600 }
  ];
  
  for (const test of testVideos) {
    console.log(`üìπ Testing ${test.file}...`);
    
    const startTime = Date.now();
    const { videoId } = await uploadVideo(test.file);
    
    // Monitor transcoding with progress tracking
    let profilesCompleted = [];
    await monitorTranscoding(videoId, (status) => {
      if (status.profilesComplete) {
        profilesCompleted.push({
          time: Date.now() - startTime,
          profiles: status.profilesComplete
        });
      }
    });
    
    const totalTime = (Date.now() - startTime) / 1000;
    console.log(`   Transcoding time: ${totalTime}s (expected: <${test.expectedTime}s)`);
    
    // Verify parallel processing (profiles should complete in groups)
    const parallelGroups = detectParallelGroups(profilesCompleted);
    assert(parallelGroups > 1, 'Should show parallel processing pattern');
    
    // Verify 75% speed improvement vs sequential
    const sequentialEstimate = test.expectedTime * 1.75;
    assert(totalTime < sequentialEstimate, 
      `Should be faster than sequential (${totalTime}s < ${sequentialEstimate}s)`);
  }
  
  console.log('‚úÖ TEST 3 PASSED: Parallel transcoding working efficiently');
};

function detectParallelGroups(progressData) {
  // Detect groups of profiles completing at similar times
  const groups = [];
  let currentGroup = [];
  
  for (let i = 0; i < progressData.length; i++) {
    if (i === 0 || progressData[i].time - progressData[i-1].time < 5000) {
      currentGroup.push(progressData[i]);
    } else {
      groups.push(currentGroup);
      currentGroup = [progressData[i]];
    }
  }
  if (currentGroup.length > 0) groups.push(currentGroup);
  
  return groups.length;
}
Test 4: Memory Management Under Load
javascript
// test/e2e/memory-management.test.js
const memoryManagementTest = async () => {
  console.log('üíæ TEST 4: Memory Management Under Load');
  
  // Test 4.1: Long Playback Session
  console.log('‚è±Ô∏è Test 4.1: 10-minute playback session...');
  const browser = await playwright.chromium.launch();
  const page = await browser.newPage();
  
  // Enable memory monitoring
  await page.evaluateOnNewDocument(() => {
    window.memoryReadings = [];
    setInterval(() => {
      if (performance.memory) {
        window.memoryReadings.push({
          time: Date.now(),
          used: performance.memory.usedJSHeapSize / (1024 * 1024),
          total: performance.memory.totalJSHeapSize / (1024 * 1024)
        });
      }
    }, 30000); // Every 30 seconds
  });
  
  await page.goto(`http://localhost:3000/video/${testVideoId}`);
  const video = await page.$('video');
  await video.click();
  
  // Play for 10 minutes
  await page.waitForTimeout(600000);
  
  const memoryData = await page.evaluate(() => window.memoryReadings);
  
  // Analyze memory growth
  const initialMemory = memoryData[0].used;
  const finalMemory = memoryData[memoryData.length - 1].used;
  const growth = finalMemory - initialMemory;
  
  console.log(`   Memory: ${initialMemory.toFixed(1)}MB ‚Üí ${finalMemory.toFixed(1)}MB (${growth.toFixed(1)}MB growth)`);
  assert(growth < 100, 'Memory growth should be < 100MB over 10 minutes');
  
  // Check for buffer cleanup events
  const bufferCleanups = await page.evaluate(() => {
    const logs = [];
    const originalLog = console.log;
    console.log = (...args) => {
      if (args[0]?.includes('buffer')) logs.push(args[0]);
      originalLog(...args);
    };
    return logs;
  });
  
  assert(bufferCleanups.length >= 3, 'Should have multiple buffer cleanups in 10 minutes');
  
  // Test 4.2: Multiple Concurrent Streams
  console.log('üîÄ Test 4.2: 5 concurrent video streams...');
  const browsers = [];
  
  for (let i = 0; i < 5; i++) {
    const browser = await playwright.chromium.launch();
    const page = await browser.newPage();
    await page.goto(`http://localhost:3000/video/${testVideoId}`);
    const video = await page.$('video');
    await video.click();
    browsers.push({ browser, page });
  }
  
  // Monitor Cloud Run memory
  const cloudRunMemory = await getCloudRunMemoryUsage();
  assert(cloudRunMemory < 14000, 'Cloud Run memory should stay under 14GB');
  
  // Cleanup
  for (const { browser } of browsers) {
    await browser.close();
  }
  
  console.log('‚úÖ TEST 4 PASSED: Memory management working correctly');
};

async function getCloudRunMemoryUsage() {
  // Query Cloud Run metrics
  const response = await exec(`
    gcloud monitoring read \\
      --project=${PROJECT_ID} \\
      --filter='metric.type="run.googleapis.com/container/memory/utilization"' \\
      --format=json
  `);
  
  const metrics = JSON.parse(response);
  return Math.max(...metrics.map(m => m.value));
}
Test 5: Load Testing - Concurrent Operations
javascript
// test/e2e/load-test.js
const loadTest = async () => {
  console.log('üî• TEST 5: Load Testing - Concurrent Operations');
  
  // Test 5.1: Concurrent Uploads
  console.log('üì§ Test 5.1: 10 concurrent uploads...');
  const uploadPromises = [];
  
  for (let i = 0; i < 10; i++) {
    uploadPromises.push(
      uploadVideo(`sample_30s.mp4`, { 
        title: `Load Test ${i}` 
      })
    );
  }
  
  const uploadResults = await Promise.allSettled(uploadPromises);
  const successful = uploadResults.filter(r => r.status === 'fulfilled');
  
  console.log(`   Uploads: ${successful.length}/10 successful`);
  assert(successful.length >= 8, 'At least 80% should succeed');
  
  // Test 5.2: Transcoding Queue
  console.log('‚öôÔ∏è Test 5.2: Monitoring transcoding queue...');
  const videoIds = successful.map(r => r.value.videoId);
  
  // Monitor all transcoding jobs
  const transcodingPromises = videoIds.map(id => 
    monitorTranscodingWithTimeout(id, 600000) // 10 min timeout
  );
  
  const transcodingResults = await Promise.allSettled(transcodingPromises);
  const completed = transcodingResults.filter(r => 
    r.status === 'fulfilled' && r.value.status === 'completed'
  );
  
  console.log(`   Transcoding: ${completed.length}/${videoIds.length} completed`);
  assert(completed.length >= videoIds.length * 0.8, 'At least 80% should transcode');
  
  // Test 5.3: CDN Performance Under Load
  console.log('üåê Test 5.3: CDN performance with concurrent requests...');
  const cdnRequests = [];
  
  for (const videoId of videoIds.slice(0, 5)) {
    for (let i = 0; i < 10; i++) {
      cdnRequests.push(
        fetch(`${CDN_BASE}/videos/${videoId}/480p/segment_000.ts`)
      );
    }
  }
  
  const startTime = Date.now();
  const cdnResults = await Promise.allSettled(cdnRequests);
  const cdnTime = Date.now() - startTime;
  
  const successful200s = cdnResults.filter(r => 
    r.status === 'fulfilled' && r.value.status === 200
  ).length;
  
  console.log(`   CDN: ${successful200s}/50 requests successful in ${cdnTime}ms`);
  assert(successful200s === 50, 'All CDN requests should succeed');
  assert(cdnTime < 5000, 'CDN should handle 50 requests in < 5 seconds');
  
  console.log('‚úÖ TEST 5 PASSED: System handles concurrent load');
};
Test Execution Script
bash
#!/bin/bash
# run_comprehensive_test.sh

set -e

echo "üé¨ Ode Islands Video Pipeline - Comprehensive Test Suite"
echo "======================================================="
echo ""

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Test results
PASSED=0
FAILED=0

run_test() {
  local test_name=$1
  local test_command=$2
  
  echo -e "${YELLOW}Running: ${test_name}${NC}"
  if $test_command; then
    echo -e "${GREEN}‚úÖ PASSED${NC}"
    ((PASSED++))
  else
    echo -e "${RED}‚ùå FAILED${NC}"
    ((FAILED++))
  fi
  echo ""
}

# Start services
echo "Starting services..."
npm run dev &
DEV_PID=$!
sleep 10

# Run tests
run_test "Happy Path Test" "npm run test:happy-path"
run_test "Error Handling Test" "npm run test:error-handling"
run_test "Parallel Performance Test" "npm run test:parallel-performance"
run_test "Memory Management Test" "npm run test:memory-management"
run_test "Load Test" "npm run test:load"

# Generate report
echo "================================================"
echo "TEST SUMMARY"
echo "================================================"
echo -e "Passed: ${GREEN}${PASSED}${NC}"
echo -e "Failed: ${RED}${FAILED}${NC}"

if [ $FAILED -eq 0 ]; then
  echo -e "${GREEN}üéâ ALL TESTS PASSED!${NC}"
  echo "The video pipeline is production-ready!"
else
  echo -e "${RED}‚ö†Ô∏è SOME TESTS FAILED${NC}"
  echo "Please review the failures above."
fi

# Cleanup
kill $DEV_PID 2>/dev/null || true

exit $FAILED
Manual Verification Checklist
Developer Console Checks
javascript
// In browser console during playback
// Check HLS instance
hlsInstance = document.querySelector('video').__hls;
console.log('Levels:', hlsInstance.levels.length);
console.log('Current Level:', hlsInstance.currentLevel);
console.log('Buffer Length:', hlsInstance.media.buffered.end(0) - hlsInstance.media.currentTime);

// Monitor buffer cleanup
originalLog = console.log;
bufferLogs = [];
console.log = function(...args) {
  if (args[0]?.includes('buffer')) {
    bufferLogs.push({ time: new Date(), message: args[0] });
  }
  originalLog.apply(console, args);
};
// After 3 minutes, check: bufferLogs
Cloud Run Monitoring
bash
# Check Cloud Run logs
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=video-transcoder" \
  --limit=50 --format=json | jq '.[] | {time: .timestamp, message: .textPayload}'

# Monitor memory usage
gcloud monitoring read \
  --project=${PROJECT_ID} \
  --filter='metric.type="run.googleapis.com/container/memory/utilization"' \
  --format="table(points.point.value.double_value, points.point.interval.end_time)"
Success Criteria
‚úÖ All Tests Pass:

 Happy path: Upload ‚Üí Transcode ‚Üí Play works end-to-end
 Error handling: All failure modes handled gracefully
 Performance: Parallel transcoding shows 75% improvement
 Memory: No leaks over 10-minute sessions
 Load: System handles 10 concurrent operations
‚úÖ Key Metrics:

 Upload success rate > 95%
 Transcoding success rate > 95%
 Buffer cleanup triggers every 2-3 minutes
 Memory growth < 100MB per 10-minute session
 Cloud Run memory < 14GB under load
 CDN response time < 100ms per segment
‚úÖ User Experience:

 Errors displayed clearly (no infinite spinners)
 Progress updates during transcoding
 Smooth playback without rebuffering
 Quality switching without interruption
Run this comprehensive test suite to validate the production-ready video pipeline!


